# This file was generated automatically. Do not edit it directly.
import json

from phc.base_client import BaseClient

# generated by datamodel-codegen:
#   filename:  patient-ml-service.json


from typing import List, Literal, Optional, Union

from pydantic import BaseModel, Extra, Field


class LabelDefinitionBase(BaseModel):

    id: Optional[str] = None
    """
    UUID uniquely identifying this label.
    """
    name: str
    """
    The unique name of the label.
    """
    description: str


class LabelDefinition(LabelDefinitionBase):
    id: str
    index: int = Field(..., ge=0, le=255)
    """
    The unique integer identifying this label, in the range [0,255]. It must never change during the life of the model because it is stored in training data as the label's identifier.
    """


class LabelsDefinitionInput(BaseModel):

    labels: List[LabelDefinitionBase]


class LabelsDefinition(BaseModel):

    labels: List[LabelDefinition]
    maxLabelIndex: int = Field(..., ge=-1, le=255)
    """
    The maximum index used by any label defined for this model over the life of the model. This field cannot be set by a user but is used to track what label indices have already been exhausted.
    """


class ClassificationProblemInput(BaseModel):

    labelDefinition: LabelsDefinitionInput


class ClassificationProblem(BaseModel):

    labelDefinition: LabelsDefinition


class ImageSegmentationArea(BaseModel):
    """
    A run-length encoded (RLE) 4 channel color image, representing the mask for a single label.
    """

    id: str
    """
    The ID of the label this mask is for.
    """
    rle: List[int]
    """
    The run-length encoded mask; an array of 8-bit unsigned integers.
    """


class ImageSegmentationLabelData(BaseModel):
    """
    A raw image segmentation, in the format LabelStudio provides.
    """

    labelType: Literal["imgSeg"]
    projectId: str
    """
    The ID of the LifeOmic project the label file is saved under.
    """
    height: int
    """
    The height of the segmentation mask in pixels.
    """
    width: int
    """
    The width of the segmentation mask in pixels.
    """
    areas: List[ImageSegmentationArea]


class LabelFileData(BaseModel):
    __root__: ImageSegmentationLabelData


class Tag(BaseModel):

    name: str
    value: str


class Tags(BaseModel):
    __root__: List[Tag]


class LabelBase(BaseModel):

    isConfirmed: Optional[bool] = None
    """
    A confirmed label is believed to be correct and may be used during training and evaluation.
    """
    lastConfirmedBy: Optional[str] = None
    """
    The email address or other identifier of the user who last confirmed this label.
    """
    updatedAt: Optional[float] = None
    """
    Timestamp for when the label was last updated or created expressed as milliseconds since the UTC epoch.
    """
    tags: Optional[Tags] = None


class Mask(BaseModel):
    """
    The fileId of an image containing per-pixel labels
    """

    fileId: str


class ImageSegmentationLabel(LabelBase):
    labelType: Literal["imgSeg"]
    mask: Mask
    """
    The fileId of an image containing per-pixel labels
    """


class ImageClassificationLabel(LabelBase):
    labelType: Literal["imgClf"]
    classes: List[float]
    """
    An array of integers representing the class(es) of the image
    """


class Label(BaseModel):
    __root__: Union[ImageSegmentationLabel, ImageClassificationLabel]


class ExampleBase(BaseModel):

    id: str
    updatedAt: float
    """
    Timestamp expressed as milliseconds since the UTC epoch.
    """


class Image(BaseModel):

    fileId: str


class ImageSegmentationExample(ExampleBase):
    exampleType: Literal["imgSeg"]
    image: Image
    label: Optional[ImageSegmentationLabel] = None


class ImageClassificationExample(ExampleBase):
    exampleType: Literal["imgClf"]
    image: Image
    label: Optional[ImageClassificationLabel] = None


class Example(BaseModel):
    __root__: Union[ImageSegmentationExample, ImageClassificationExample]


class FhirCodesFilter(BaseModel):
    """
    Used to find FHIR resources containing a type code that equals any value in the codes array
    """

    filterType: Literal["FhirCodesFilter"]
    codes: List[str] = Field(..., max_items=10, min_items=1)


class CategoricalParameterSpace(BaseModel):

    type: Literal["categorical"]
    name: str
    values: List[str]


class NumericScale(BaseModel):
    __root__: Literal["auto", "linear", "log", "reverseLog"]


class NumericParameterSpace(BaseModel):

    name: str
    min: float
    max: float
    scale: NumericScale


class ContinuousParameterSpace(NumericParameterSpace):
    type: Literal["continuous"]


class IntegerParameterSpace(NumericParameterSpace):
    type: Literal["integer"]


class ParameterSpace(BaseModel):
    __root__: Union[
        CategoricalParameterSpace,
        ContinuousParameterSpace,
        IntegerParameterSpace,
    ]


class OptimizationDirection(BaseModel):
    __root__: Literal["minimize", "maximize"]


class OptimizationObjective(BaseModel):

    direction: OptimizationDirection
    metric: str


class MetricDefinition(BaseModel):
    """
    Camel-cased mirror of https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_MetricDefinition.html.
    """

    name: str
    regex: str


class TuningJobTrainingApproach(BaseModel):

    type: Literal["tuningJob"]
    trainingImage: str = Field(
        ...,
        regex="^[0-9]+\\.dkr.ecr.[-a-z0-9]+\\.amazonaws\\.com\\/[-_a-zA-Z0-9]+:[-_a-zA-Z0-9]+$",
    )
    """
    An aws ecr image uri of the form <account-id>.dkr.ecr.<region>.amazonaws.com/<repo-name>:<tag>
    """
    metricDefinitions: List[MetricDefinition]
    objective: OptimizationObjective
    """
    The metric to optimize during the hyperparameter tuning process.
    """
    searchSpace: List[ParameterSpace]
    """
    The hyperparameter search space to explore during hyperparameter tuning.
    """
    maxTrials: Optional[int] = Field(None, ge=1, le=30)
    """
    The maximum number of candidate models to consider in a given model run.
    """
    retrainEvery: Optional[float] = None
    """
    If provided, the model will automatically be retrained if this many milliseconds have passed since the last run. Models will not be retrained more frequently than once per day, and this policy is only checked once per day, so more than this many milliseconds may actually pass before the model is retrained.
    """


class TrainingApproach(BaseModel):
    __root__: TuningJobTrainingApproach


class DeployApproachBase(BaseModel):

    inferenceImage: str = Field(
        ...,
        regex="^[0-9]+\\.dkr.ecr.[-a-z0-9]+\\.amazonaws\\.com\\/[-_a-zA-Z0-9]+:[-_a-zA-Z0-9]+$",
    )
    """
    An aws ecr image uri of the form <account-id>.dkr.ecr.<region>.amazonaws.com/<repo-name>:<tag>
    """


class EdgeDeployApproach(DeployApproachBase):
    type: Literal["edge"]


class CloudDeployApproach(DeployApproachBase):
    type: Literal["cloud"]


class DeployApproach(BaseModel):
    __root__: Union[EdgeDeployApproach, CloudDeployApproach]


class DatasetConfigBase(BaseModel):

    name: str
    description: str


class ModelConfigBase(BaseModel):

    name: str
    description: str
    trainingApproach: TrainingApproach
    deployApproach: DeployApproach
    datasetId: str
    """
    The ID of the configuration that defines the dataset this model will be trained on.
    """


class ModelConfigInput(ModelConfigBase):
    pass


class ModelConfig(ModelConfigBase):
    id: str
    """
    UUID uniquely identifying this model config.
    """
    accountId: str
    championId: Optional[str] = None
    """
    The ID of the champion model run for this model config.
    """


class Metric(BaseModel):

    name: str
    """
    The name of the metric e.g. "Cross Entopy Loss", "Accuracy", "F1 Macro", etc.
    """
    description: Optional[str] = None
    """
    A description of the metric to help people understand what it means and represents.
    """
    value: float
    stage: Literal["training", "evaluation"]
    """
    @deprecated The stage of the model run this metric was computed in. If `training`, the metric could have been computed over the train or val set. If `evaluation`, the metric was computed over the test set.
    """
    direction: Optional[OptimizationDirection] = None
    """
    The optimization direction for this metric. E.g. `minimize` means a smaller value for this metric is better. This direction is just used as metadata about the metric value, and does not mean this metric will be optimized during hyperparameter tuning.
    """


class ApprovalChoice(BaseModel):
    __root__: Literal["approved", "rejected"]


class ApprovalDecisionInput(BaseModel):

    description: Optional[str] = None
    """
    Reasoning, justification, or other notes to associate with the decision.
    """
    decision: ApprovalChoice


class ApprovalDecisionBase(ApprovalDecisionInput):
    timestamp: float
    """
    Timestamp of when the decision was made. Expressed as milliseconds since the UTC epoch.
    """


class SystemApprovalDecision(ApprovalDecisionBase):
    actor: Literal["system"]


class UserApprovalDecision(ApprovalDecisionBase):
    actor: Literal["user"]
    user: str


class ApprovalDecision(BaseModel):
    __root__: Union[SystemApprovalDecision, UserApprovalDecision]


class RunMetrics(BaseModel):

    challenger: List[Metric]
    """
    Metrics about how the model version trained in this run (the challenger) performed on this run's test set.
    """
    champion: List[Metric]
    """
    Metrics about how the current best model (the champion) performed on this run's test set.
    """


class Parameter(BaseModel):
    """
    A hyperparameter value. The values themselves are represented as strings.
    """

    name: str
    value: str


class LogEvent(BaseModel):
    """
    An event logged by some component of a model run, as well as metadata about the log event.
    """

    type: Literal["logEntry"]
    timestamp: float
    """
    The time when the log event occurred, expressed as milliseconds since the unix epoch.
    """
    payload: str
    """
    The actual body of the logged event.
    """
    stage: str
    """
    The model run's stage or component that produced this log event.
    """


class ImageSegmentationPredictionRequest(BaseModel):

    predictionType: Literal["imgSeg"]
    """
    The type of prediction requested. This must be the same as the problem type in your model config.
    """
    exampleId: str
    """
    The ID of the example a prediction is being requested for. It is the ID of a DocumentReference FHIR record which references the image file a segmenation mask will be generated for.
    """


class ImageClassificationPredictionRequest(BaseModel):

    predictionType: Literal["imgClf"]
    """
    The type of prediction requested. This must be the same as the problem type in your model config.
    """
    exampleId: str
    """
    The ID of the example a prediction is being requested for. It is the ID of a DocumentReference FHIR record which references the image file a classification will be generated for.
    """


class PredictionRequest(BaseModel):
    __root__: Union[
        ImageSegmentationPredictionRequest, ImageClassificationPredictionRequest
    ]


class ImageClassificationPrediction(BaseModel):

    index: int
    """
    The index of a classification label.
    """
    value: bool
    """
    This value will be `true` if the model predicted this label being present on the example; `false` otherwise.
    """
    confidence: float
    """
    The confidence score of the prediction. If this value is greater than the model's decision threshold, `value` will be `true`.
    """


class ImageClassificationPredictionResponse(BaseModel):

    predictionType: Literal["imgClf"]
    predictions: List[ImageClassificationPrediction]
    """
    A prediction for every label defined by the model.
    """


class PredictionResponse(BaseModel):
    __root__: ImageClassificationPredictionResponse


class CreateModelResponse(BaseModel):

    model: ModelConfig


class GetModelsResponse(BaseModel):

    models: List[ModelConfig]


class UpdateModelResponse(BaseModel):

    model: ModelConfig


class DeleteModelResponse(BaseModel):

    id: str
    """
    The id of the model that was deleted.
    """


class GetModelResponse(BaseModel):

    model: Optional[ModelConfig] = None


class CreateRunResponse(BaseModel):

    runId: str
    """
    The id of the newly created run. Can be used to fetch data about the run.
    """


class GetModelArtifactResponse(BaseModel):

    url: str


class GetModelLogsParams(BaseModel):
    filter: Optional[str] = None
    """
    An optional field used to filter the log events. This parameter supports AWS CloudWatch Logs' filter and pattern syntax. See https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/FilterAndPatternSyntax.html for instructions on how to write filters.
    """
    marker: Optional[str] = None
    """
    Passed in to control which page of results is retrieved. Passing `undefined` for this parameter will retrieve the first page of results. The marker for the next page will be present in the response to this request.
    """
    limit: Optional[int] = Field(None, ge=1, le=10000)
    """
    The maximum number of events to return. The default is to return 10,000 -- the largest allowed.
    """


class GetModelLogsResponse(BaseModel):

    events: List[LogEvent]
    marker: Optional[str] = None
    """
    A marker used for pagination. Pass it in the request body to retrieve the next page of results. This field will be undefined if the output is not truncated.
    """


class CreateApprovalDecisionResponse(BaseModel):

    approvalDecision: UserApprovalDecision


class DeleteDatasetResponse(BaseModel):

    id: str
    """
    The id of the dataset that was deleted.
    """


class GetDatasetExamplesParams(BaseModel):
    projectId: str
    hasLabel: Optional[Literal["true", "false"]] = None
    hasUnconfirmedLabel: Optional[Literal["true", "false"]] = None
    """
    Allows for fetching examples that have unconfirmed labels.
    """
    marker: Optional[str] = None
    patientId: Optional[str] = None
    cohortId: Optional[str] = None


class GetDatasetExamplesResponse(BaseModel):

    examples: List[Example]
    marker: Optional[str] = None
    """
    A marker used for pagination. Pass it in the request body to retrieve the next page of results. This field will be undefined if the output is not truncated.
    """


class GetDatasetExampleParams(BaseModel):
    projectId: str
    cohortId: Optional[str] = None


class GetDatasetExampleResponse(BaseModel):

    example: Optional[Example] = None


class GetDatasetLabelFileResponse(BaseModel):

    labelData: Optional[LabelFileData] = None


class PutDatasetLabelFileResponse(BaseModel):

    fileId: str
    """
    The id of the file-service file the label file was saved to.
    """


class ImageSegmentationProblemBase(BaseModel):

    problemType: Literal["imgSeg"]
    trainingDataFilter: FhirCodesFilter
    """
    Used to filter through patient data to identify image/mask pairs for model training.
    """


class ImageSegmentationProblemInput(
    ClassificationProblemInput, ImageSegmentationProblemBase
):
    pass


class ImageSegmentationProblem(
    ClassificationProblem, ImageSegmentationProblemBase
):
    pass


class ImageClassificationProblemBase(BaseModel):

    problemType: Literal["imgClf"]
    trainingDataFilter: FhirCodesFilter
    """
    Used to filter through patient data to identify the input images for the model.
    """


class ImageClassificationProblemInput(
    ClassificationProblemInput, ImageClassificationProblemBase
):
    pass


class ImageClassificationProblem(
    ClassificationProblem, ImageClassificationProblemBase
):
    pass


class MlProblemDefinitionInput(BaseModel):
    __root__: Union[
        ImageSegmentationProblemInput, ImageClassificationProblemInput
    ]


class MlProblemDefinition(BaseModel):
    __root__: Union[ImageSegmentationProblem, ImageClassificationProblem]


class DatasetConfigInput(DatasetConfigBase):
    problemDefinition: MlProblemDefinitionInput


class DatasetConfig(DatasetConfigBase):
    id: str
    """
    UUID uniquely identifying this dataset config.
    """
    accountId: str
    problemDefinition: MlProblemDefinition


class ModelRun(BaseModel):

    id: str
    """
    UUID uniquely identifying this model run.
    """
    slug: str
    """
    Human-readable slug that acts as an auto-generated name for the run. This field is not guaranteed to be unique, so cannot be used reliably as a unique identifier.
    """
    modelId: str
    """
    ID of the model config this run was produced for.
    """
    accountId: str
    modelArtifactUri: Optional[str] = None
    """
    S3 URI location where the final trained model artifact produced by this run is saved to.
    """
    status: Literal["running", "succeeded", "failed"]
    error: Optional[str] = None
    """
    If `status` is 'failed', gives the reason why the run failed.
    """
    deployStatus: Optional[Literal["deploying", "succeeded", "failed"]] = None
    deployError: Optional[str] = None
    """
    If `deployStatus` is 'failed', gives the reason why deploying the model endpoint failed
    """
    start: float
    """
    Timestamp of when the run started. Expressed as milliseconds since the UTC epoch.
    """
    end: Optional[float] = None
    """
    Timestamp of when the run ended. Expressed as milliseconds since the UTC epoch.
    """
    isArchived: Optional[bool] = None
    """
    True if this run has been archived. Archived runs' related artifacts are deleted, and they can no longer be deployed.
    """
    hyperparameters: List[Parameter]
    """
    The hyperparameters used to train the model version created by this run.
    """
    championId: Optional[str] = None
    """
    The ID of the model run that was the current champion while this model run was running. All champion metrics on this model run represent that champion's performance on this run's dataset.
    """
    metrics: RunMetrics
    approvals: List[ApprovalDecision]
    """
    Decisions made by various actors representing whether they think this model version should be used in production and become the new champion.
    """
    problemDefinition: MlProblemDefinition
    trainingApproach: TrainingApproach
    deployApproach: DeployApproach


class GetRunsResponse(BaseModel):

    runs: List[ModelRun]


class GetRunResponse(BaseModel):

    run: Optional[ModelRun] = None


class CreateDatasetResponse(BaseModel):

    dataset: DatasetConfig


class GetDatasetsResponse(BaseModel):

    datasets: List[DatasetConfig]


class UpdateDatasetResponse(BaseModel):

    dataset: DatasetConfig


class GetDatasetResponse(BaseModel):

    dataset: Optional[DatasetConfig] = None


class PatientML(BaseClient):
    def create_model(self, body: ModelConfigInput):
        """Creates a new model via a model config object."""
        res = self._api_call(
            api_path="/v1/patient-ml/models",
            http_verb="POST",
            json=json.loads(body.json(exclude_none=True)),
        )
        return CreateModelResponse.parse_obj(res.data)

    def get_models(self):
        """Gets all model configs for an account."""
        res = self._api_call(api_path="/v1/patient-ml/models", http_verb="GET")
        return GetModelsResponse.parse_obj(res.data)

    def update_model(self, id: str, body: ModelConfigInput):
        """Updates a model config."""
        res = self._api_call(
            api_path=f"/v1/patient-ml/models/{id}",
            http_verb="PUT",
            json=json.loads(body.json(exclude_none=True)),
        )
        return UpdateModelResponse.parse_obj(res.data)

    def delete_model(self, id: str):
        """Deletes a model."""
        res = self._api_call(
            api_path=f"/v1/patient-ml/models/{id}", http_verb="DELETE"
        )
        return DeleteModelResponse.parse_obj(res.data)

    def get_model(self, id: str):
        """Gets a model config."""
        res = self._api_call(
            api_path=f"/v1/patient-ml/models/{id}", http_verb="GET"
        )
        return GetModelResponse.parse_obj(res.data)

    def create_run(self, model_id: str):
        """Begins a new ML run for a given model."""
        res = self._api_call(
            api_path=f"/v1/patient-ml/models/{model_id}/runs", http_verb="POST"
        )
        return CreateRunResponse.parse_obj(res.data)

    def get_runs(self, model_id: str):
        """Gets data for all ML runs for a model."""
        res = self._api_call(
            api_path=f"/v1/patient-ml/models/{model_id}/runs", http_verb="GET"
        )
        return GetRunsResponse.parse_obj(res.data)

    def get_run(self, model_id: str, run_id: str):
        """Gets data for a particular run."""
        res = self._api_call(
            api_path=f"/v1/patient-ml/models/{model_id}/runs/{run_id}",
            http_verb="GET",
        )
        return GetRunResponse.parse_obj(res.data)

    def get_model_artifact(self, model_id: str, run_id: str):
        """Gets a url that can be used to download the model artifact for a particular run."""
        res = self._api_call(
            api_path=f"/v1/patient-ml/models/{model_id}/runs/{run_id}/model-artifact",
            http_verb="GET",
        )
        return GetModelArtifactResponse.parse_obj(res.data)

    def get_model_logs(
        self, model_id: str, run_id: str, params: GetModelLogsParams
    ):
        """Gets the log events for a particular run."""
        res = self._api_call(
            api_path=f"/v1/patient-ml/models/{model_id}/runs/{run_id}/logs",
            http_verb="GET",
            params=json.loads(params.json(exclude_none=True)),
        )
        return GetModelLogsResponse.parse_obj(res.data)

    def create_approval_decision(
        self, model_id: str, run_id: str, body: ApprovalDecisionInput
    ):
        """Adds a new approval decision to a model run."""
        res = self._api_call(
            api_path=f"/v1/patient-ml/models/{model_id}/runs/{run_id}/approvals",
            http_verb="POST",
            json=json.loads(body.json(exclude_none=True)),
        )
        return CreateApprovalDecisionResponse.parse_obj(res.data)

    def predict(self, model_id: str):
        """Constructs an example and submits it to the referenced model for inference. The model's output predictions are then returned. The example is retrieved based on the model's problem type and the provided query parameters. Note that this route is only supported for models using the `cloud` deploy type, and which have a currently deployed model version (champion)."""
        res = self._api_call(
            api_path=f"/v1/patient-ml/models/{model_id}/predictions",
            http_verb="GET",
        )
        return PredictionResponse.parse_obj(res.data)

    def create_dataset(self, body: DatasetConfigInput):
        """Creates a new dataset via a dataset config object."""
        res = self._api_call(
            api_path="/v1/patient-ml/datasets",
            http_verb="POST",
            json=json.loads(body.json(exclude_none=True)),
        )
        return CreateDatasetResponse.parse_obj(res.data)

    def get_datasets(self):
        """Gets all dataset configs in the account."""
        res = self._api_call(
            api_path="/v1/patient-ml/datasets", http_verb="GET"
        )
        return GetDatasetsResponse.parse_obj(res.data)

    def update_dataset(self, id: str, body: DatasetConfigInput):
        """Updates a dataset config."""
        res = self._api_call(
            api_path=f"/v1/patient-ml/datasets/{id}",
            http_verb="PUT",
            json=json.loads(body.json(exclude_none=True)),
        )
        return UpdateDatasetResponse.parse_obj(res.data)

    def delete_dataset(self, id: str):
        """Deletes a dataset."""
        res = self._api_call(
            api_path=f"/v1/patient-ml/datasets/{id}", http_verb="DELETE"
        )
        return DeleteDatasetResponse.parse_obj(res.data)

    def get_dataset(self, id: str):
        """Gets a dataset config."""
        res = self._api_call(
            api_path=f"/v1/patient-ml/datasets/{id}", http_verb="GET"
        )
        return GetDatasetResponse.parse_obj(res.data)

    def get_dataset_examples(
        self, dataset_id: str, params: GetDatasetExamplesParams
    ):
        """Fetches a page of training data examples for data labeling."""
        res = self._api_call(
            api_path=f"/v1/patient-ml/datasets/{dataset_id}/examples",
            http_verb="GET",
            params=json.loads(params.json(exclude_none=True)),
        )
        return GetDatasetExamplesResponse.parse_obj(res.data)

    def get_dataset_example(
        self, dataset_id: str, example_id: str, params: GetDatasetExampleParams
    ):
        """Fetches a single training data example for data labeling."""
        res = self._api_call(
            api_path=f"/v1/patient-ml/datasets/{dataset_id}/examples/{example_id}",
            http_verb="GET",
            params=json.loads(params.json(exclude_none=True)),
        )
        return GetDatasetExampleResponse.parse_obj(res.data)

    def put_dataset_label(self, dataset_id: str, example_id: str, body: Label):
        """Updates the label for a training data example."""
        res = self._api_call(
            api_path=f"/v1/patient-ml/datasets/{dataset_id}/examples/{example_id}/label",
            http_verb="PUT",
            json=json.loads(body.json(exclude_none=True)),
        )
        return Example.parse_obj(res.data)

    def get_dataset_label_file(self, dataset_id: str, example_id: str):
        """Retrieves the label file for the given example, if it exists, and converts it to the format LabelStudio expects."""
        res = self._api_call(
            api_path=f"/v1/patient-ml/datasets/{dataset_id}/examples/{example_id}/label-file",
            http_verb="GET",
        )
        return GetDatasetLabelFileResponse.parse_obj(res.data)

    def put_dataset_label_file(
        self, dataset_id: str, example_id: str, body: LabelFileData
    ):
        """Preprocesses the label data and updates the label file for a training data example. This is done for ML problem types that store their labels as independent files, such as image segmentation. For those problem types, The label data is not stored on a label FHIR record, but in a separate file-service file, and pointed to by a label FHIR record."""
        res = self._api_call(
            api_path=f"/v1/patient-ml/datasets/{dataset_id}/examples/{example_id}/label-file",
            http_verb="PUT",
            json=json.loads(body.json(exclude_none=True)),
        )
        return PutDatasetLabelFileResponse.parse_obj(res.data)
